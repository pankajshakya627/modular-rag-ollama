# High-Level Design (HLD)

## ğŸ“Œ Overview

**modular-rag-ollama** is a production-grade Retrieval-Augmented Generation (RAG) framework designed for **local-first AI** applications. It combines state-of-the-art retrieval techniques with LLM-powered generation, all running **completely locally** using Ollama.

### Why This Project Exists

Traditional RAG implementations suffer from several issues:

| Problem                                    | Our Solution                                   |
| ------------------------------------------ | ---------------------------------------------- |
| Basic keyword/vector search misses context | **Hybrid Search** (BM25 + Dense vectors)       |
| Query-document vocabulary mismatch         | **HyDE** (Hypothetical Document Embeddings)    |
| Flat document retrieval lacks hierarchy    | **RAPTOR** (Recursive Abstractive Processing)  |
| Initial retrieval quality is "good enough" | **Reranking** (Cross-Encoder, ColBERT)         |
| Simple pipelines lack flexibility          | **LangGraph** orchestration for stateful flows |
| Cloud dependency for LLMs                  | **Ollama** for 100% local execution            |

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              FastAPI Layer                                  â”‚
â”‚                         (REST API + WebSocket)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         LangGraph Orchestrator                              â”‚
â”‚                    (State Machine for RAG Pipeline)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Query   â”‚â†’ â”‚Retrieval â”‚â†’ â”‚ Rerank   â”‚â†’ â”‚ Generate â”‚â†’ â”‚ Response â”‚      â”‚
â”‚  â”‚ Analysis â”‚  â”‚  Stage   â”‚  â”‚  Stage   â”‚  â”‚  Stage   â”‚  â”‚ Synthesisâ”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                           â”‚                           â”‚
        â–¼                           â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Retrieval   â”‚         â”‚   Reranking   â”‚         â”‚  Generation   â”‚
â”‚  Components   â”‚         â”‚  Components   â”‚         â”‚  Components   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Vector Storeâ”‚         â”‚ â€¢ CrossEncoderâ”‚         â”‚ â€¢ AnswerGen   â”‚
â”‚ â€¢ BM25 Search â”‚         â”‚ â€¢ ColBERT     â”‚         â”‚ â€¢ Response    â”‚
â”‚ â€¢ HyDE        â”‚         â”‚               â”‚         â”‚   Synthesizer â”‚
â”‚ â€¢ RAPTOR      â”‚         â”‚               â”‚         â”‚               â”‚
â”‚ â€¢ Hybrid      â”‚         â”‚               â”‚         â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                                   â”‚
        â”‚                                                   â”‚
        â–¼                                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              Core Layer                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   LLMWrapper    â”‚    â”‚ EmbeddingWrapperâ”‚    â”‚  Configuration  â”‚       â”‚
â”‚  â”‚  (ChatOllama)   â”‚    â”‚ (OllamaEmbed)   â”‚    â”‚    (YAML)       â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚      Ollama Server          â”‚
                     â”‚  (Local LLM + Embeddings)   â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Major Components

### 1. Core Layer

| Component          | Purpose                               | Technology                          |
| ------------------ | ------------------------------------- | ----------------------------------- |
| `LLMWrapper`       | Unified interface for text generation | `langchain-ollama.ChatOllama`       |
| `EmbeddingWrapper` | Unified interface for embeddings      | `langchain-ollama.OllamaEmbeddings` |
| `Configuration`    | YAML-based settings management        | Pydantic Settings                   |

**Why ChatOllama over basic Ollama?**

- Supports chat-style message history
- Returns structured `AIMessage` objects
- Better integration with LangChain Expression Language (LCEL)

---

### 2. Document Processing

| Chunker            | When to Use              | How It Works                                        |
| ------------------ | ------------------------ | --------------------------------------------------- |
| `RecursiveChunker` | General documents        | Splits by hierarchy: paragraphs â†’ sentences â†’ words |
| `SemanticChunker`  | Context-aware splitting  | Groups sentences by embedding similarity            |
| `FixedSizeChunker` | Predictable token counts | Hard splits at N characters + overlap               |

**Issue Solved:** Naive fixed-size chunking breaks semantic meaning. Recursive and semantic chunkers preserve context boundaries.

---

### 3. Retrieval Components

#### Vector Store (`LangChainChromaVectorStore`)

- **What:** Stores document embeddings for similarity search
- **How:** Uses ChromaDB with Ollama embeddings
- **Why:** Fast approximate nearest neighbor search at scale

#### Hybrid Search

- **What:** Combines sparse (BM25) + dense (vector) retrieval
- **How:** Reciprocal Rank Fusion (RRF) to merge rankings
- **Why:** BM25 catches exact keyword matches that embeddings miss

#### HyDE (Hypothetical Document Embeddings)

- **What:** Generates a "fake answer" and searches for similar docs
- **How:** LLM writes hypothetical content â†’ embed â†’ search
- **Why:** Bridges vocabulary gap between queries and documents

#### RAPTOR (Recursive Abstractive Processing for Tree-Organized Retrieval)

- **What:** Builds a hierarchical summary tree over documents
- **How:** Clusters chunks â†’ generates summaries â†’ clusters summaries
- **Why:** Enables multi-hop reasoning across document sections

---

### 4. Reranking Components

| Reranker               | Approach                      | Trade-off              |
| ---------------------- | ----------------------------- | ---------------------- |
| `CrossEncoderReranker` | Full attention over query+doc | High accuracy, slower  |
| `ColBERTReranker`      | Late interaction (MaxSim)     | Balanced speed/quality |

**Issue Solved:** Initial retrieval is fast but imprecise. Rerankers add a second-stage precision boost on the top-K candidates.

---

### 5. Generation Components

| Component             | Purpose                                                |
| --------------------- | ------------------------------------------------------ |
| `AnswerGenerator`     | Generates answers from context with source attribution |
| `ResponseSynthesizer` | Merges outputs from multiple retrieval methods         |

---

### 6. Orchestration (LangGraph)

The `RAGGraph` class implements a **state machine** using LangGraph:

```
START â†’ Query Analysis â†’ [Dense Retrieval, Sparse Retrieval, HyDE] â†’
        Fusion â†’ Reranking â†’ Generation â†’ END
```

**Why LangGraph?**

- Explicit control flow (not just chains)
- State persistence across steps
- Easy to add retries, loops, and conditional branches

---

## ğŸ”„ Data Flow

```mermaid
flowchart LR
    A[User Query] --> B[Query Analysis]
    B --> C{Decompose?}
    C -->|Yes| D[Sub-queries]
    C -->|No| E[Single Query]
    D --> F[Parallel Retrieval]
    E --> F
    F --> G[Hybrid Fusion]
    G --> H[Reranking]
    H --> I[Context Selection]
    I --> J[Answer Generation]
    J --> K[Response + Sources]
```

---

## ğŸ› ï¸ Technology Stack

| Layer         | Technology               |
| ------------- | ------------------------ |
| LLM           | Ollama (local)           |
| Orchestration | LangGraph                |
| Chains        | LangChain Core (LCEL)    |
| Vector Store  | ChromaDB                 |
| Sparse Search | rank_bm25                |
| Reranking     | HuggingFace Transformers |
| API           | FastAPI + Uvicorn        |
| Config        | Pydantic Settings + YAML |

---

## ğŸ“ Project Structure

```
modular-rag-ollama/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/               # LLM, Embedding, Config
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ retrieval/      # Vector store, HyDE, RAPTOR, Hybrid
â”‚   â”‚   â”œâ”€â”€ reranking/      # CrossEncoder, ColBERT
â”‚   â”‚   â”œâ”€â”€ generation/     # Answer generator, Response synthesizer
â”‚   â”‚   â””â”€â”€ orchestration/  # LangGraph RAG workflow
â”‚   â”œâ”€â”€ api/                # FastAPI endpoints
â”‚   â””â”€â”€ utils/              # Evaluation metrics
â”œâ”€â”€ config/                 # YAML configuration
â”œâ”€â”€ data/                   # Documents and vector store
â”œâ”€â”€ tests/                  # Pytest tests
â””â”€â”€ docs/                   # HLD, LLD, Architecture
```
